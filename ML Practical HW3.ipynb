{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "homework_practice_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csMaH5hpuVTz"
      },
      "source": [
        "# Машинное обучение, РЭШ\n",
        "\n",
        "## [Практическое задание 3. Градиентный спуск своими руками](https://www.youtube.com/watch?v=dQw4w9WgXcQ)\n",
        "\n",
        "### Общая информация\n",
        "Дата выдачи: 14.11.2020\n",
        "\n",
        "Мягкий дедлайн: 23:59MSK 21.11.2020 (за каждый день просрочки снимается 1 балл)\n",
        "\n",
        "Жесткий дедлайн: 23:59MSK 23.11.2020"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRJFT5yPuVUC"
      },
      "source": [
        "### О задании\n",
        "\n",
        "В данном задании необходимо реализовать обучение линейной регрессии с помощью различных вариантов градиентного спуска.\n",
        "\n",
        "\n",
        "### Оценивание и штрафы\n",
        "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 10 баллов.\n",
        "\n",
        "Сдавать задание после указанного срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
        "\n",
        "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
        "\n",
        "Неэффективная реализация кода может негативно отразиться на оценке.\n",
        "\n",
        "Все ответы должны сопровождаться кодом или комментариями о том, как они были получены.\n",
        "\n",
        "\n",
        "### Формат сдачи\n",
        "Задания загружаются на my.nes. Присылать необходимо ноутбук с выполненным заданием. \n",
        "\n",
        "Для удобства проверки самостоятельно посчитайте свою максимальную оценку (исходя из набора решенных задач) и укажите ниже.\n",
        "\n",
        "**Оценка**: 10!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-HrP6yvuVUE"
      },
      "source": [
        "## Реализация градиентного спуска\n",
        "\n",
        "Реализуйте линейную регрессию с функцией потерь MSE, обучаемую с помощью:\n",
        "\n",
        "**Задание 1 (2 балл)** Градиентного спуска;\n",
        "\n",
        "**Задание 2 (3 балла)** Стохастического градиентного спуска;\n",
        "\n",
        "Во всех пунктах необходимо соблюдать следующие условия:\n",
        "\n",
        "* Все вычисления должны быть векторизованы;\n",
        "* Циклы средствами python допускается использовать только для итераций градиентного спуска;\n",
        "* В качестве критерия останова необходимо использовать (одновременно):\n",
        "\n",
        "    * проверку на евклидовую норму разности весов на двух соседних итерациях (например, меньше некоторого малого числа порядка $10^{-6}$, задаваемого параметром `tolerance`);\n",
        "    * достижение максимального числа итераций (например, 10000, задаваемого параметром `max_iter`).\n",
        "* Чтобы проследить, что оптимизационный процесс действительно сходится, будем использовать атрибут класса `loss_history` — в нём после вызова метода `fit` должны содержаться значения функции потерь для всех итераций, начиная с первой (до совершения первого шага по антиградиенту);\n",
        "* Инициализировать веса можно случайным образом или нулевым вектором. \n",
        "\n",
        "\n",
        "Ниже приведён шаблон класса, который должен содержать код реализации каждого из методов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsRKuxmtw-TO"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzu1xnsCuVUG"
      },
      "source": [
        "class LinearReg(BaseEstimator):\n",
        "    def __init__(self, gd_type='full', \n",
        "                 tolerance=1e-6, max_iter=1000, w0=None, eta=1e-2, seed = 111):\n",
        "        \"\"\"\n",
        "        gd_type: 'full' or 'stochastic'\n",
        "        tolerance: for stopping gradient descent\n",
        "        max_iter: maximum number of steps in gradient descent\n",
        "        w0: np.array of shape (d) - init weights\n",
        "        eta: learning rate\n",
        "        alpha: momentum coefficient\n",
        "        \"\"\"\n",
        "        self.gd_type = gd_type\n",
        "        self.tolerance = tolerance\n",
        "        self.max_iter = max_iter\n",
        "        self.w0 = w0\n",
        "        self.w = None\n",
        "        self.eta = eta\n",
        "        self.loss_history = None # list of loss function values at each training iteration\n",
        "        self.seed = seed \n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (ell, d)\n",
        "        y: np.array of shape (ell)\n",
        "        ---\n",
        "        output: self\n",
        "        \"\"\"\n",
        "        np.random.seed(self.seed)\n",
        "\n",
        "        if (self.w0 == None):\n",
        "          self.w0 = np.zeros(X.shape[1])\n",
        "\n",
        "        self.w = self.w0\n",
        "        self.loss_history = [self.calc_loss(X, y)]\n",
        "\n",
        "        iter = 0\n",
        "        need_to_continue = True\n",
        "\n",
        "        while need_to_continue:\n",
        "          \n",
        "          if self.gd_type == 'full':\n",
        "            step = self.calc_gradient(X,y)\n",
        "            self.w -= self.eta*step\n",
        "            need_to_continue = np.logical_and(iter <= self.max_iter,\n",
        "                                            np.sqrt(np.mean(((self.eta*step)**2))) >= self.tolerance)\n",
        "          elif self.gd_type == 'stochastic':\n",
        "            i = np.random.randint(0,X.shape[0])\n",
        "            step = self.eta * self.calc_gradient(X[i], y[i])\n",
        "            # В качестве learning rate будем использовать (1/k)**alpha, где k - номер итерации (удовл. условию Роббинса-Монро)\n",
        "            self.w -= step/((iter+1)**0.51)\n",
        "            need_to_continue = np.logical_and(iter <= self.max_iter,\n",
        "                                            np.sqrt(np.mean(((step/(iter+1))**2))) >= self.tolerance)\n",
        "          else:\n",
        "            raise Exception('The method {0} is not implemented yet'.format(self.gd_type))\n",
        "\n",
        "          self.loss_history = np.append(self.loss_history, self.calc_loss(X, y))\n",
        "          iter+=1\n",
        "        return self\n",
        "    \n",
        "    def predict(self, X):\n",
        "        if self.w is None:\n",
        "            raise Exception('Not trained yet')\n",
        "        return X @ self.w\n",
        "    \n",
        "    def calc_gradient(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (ell, d) (ell can be equal to 1 if stochastic)\n",
        "        y: np.array of shape (ell)\n",
        "        ---\n",
        "        output: np.array of shape (d)\n",
        "        \"\"\"\n",
        "        return 2/X.shape[0] * np.dot(X.T, X@self.w - y)\n",
        "\n",
        "    def calc_loss(self, X, y):\n",
        "        \"\"\"\n",
        "        X: np.array of shape (ell, d)\n",
        "        y: np.array of shape (ell)\n",
        "        ---\n",
        "        output: float \n",
        "        \"\"\" \n",
        "        return mean_squared_error(y, X @ self.w)\n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAGrUd74uVUX"
      },
      "source": [
        "**Задание 3 (0 баллов)**. \n",
        "* Загрузите данные из домашнего задания 2 ([train.csv](https://www.kaggle.com/c/nyc-taxi-trip-duration/data));\n",
        "* Разбейте выборку на обучающую и тестовую в отношении 7:3 с random_seed=0;\n",
        "* Преобразуйте целевую переменную `trip_duration` как $\\hat{y} = \\log{(y + 1)}$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iCwCmGnuVUY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64c2181-4c18-4061-8824-fda7ce299d9a"
      },
      "source": [
        "#!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c nyc-taxi-trip-duration"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.9 / client 1.5.4)\n",
            "sample_submission.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "test.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghEu5Er2whC_"
      },
      "source": [
        "train = pd.read_csv('train.zip', parse_dates=['pickup_datetime'])\n",
        "train['log_trip_duration'] = np.log1p(train['trip_duration']) \n",
        "train['p_date'] = train['pickup_datetime'].dt.date\n",
        "train['p_date'] = train['p_date'].apply(lambda x: x.timetuple().tm_yday)\n",
        "dtrain, dtest = train_test_split(train, test_size = 0.3, random_state = 0)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaX55pBGuVUd"
      },
      "source": [
        "**Задание 4 (3 балла)**. Обучите и провалидируйте модели на данных из предыдущего пункта, сравните качество между методами по метрикам MSE и $R^2$. Исследуйте влияние параметров `max_iter` и `eta` на процесс оптимизации. Согласуется ли оно с вашими ожиданиями?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlD1yPFV1Aim"
      },
      "source": [
        "Далее мы будем обучать линейную модель (с константой), состоящую всего из одной вещественной переменной: p_date. Ведь наша задача посмотреть на сходимость, а не построить лучшую модель.\n",
        "\n",
        "Нам надо отмасштабировать переменные обучающей выборки. При этом, необходимо запомнить параметры масштаба и применять их же для последующего масштабирования теста! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE4ZTC5h3GMd"
      },
      "source": [
        "X = dtrain['p_date']\n",
        "y = np.array(dtrain['log_trip_duration'])\n",
        "\n",
        "# Масштабируем\n",
        "means = np.mean(X, axis=0)\n",
        "sds = np.std(X, axis = 0)\n",
        "X = (X-means)/sds\n",
        "\n",
        "# И добавляем константу\n",
        "X = np.c_[np.ones(X.shape[0]),X]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzUvsFfLEDCO"
      },
      "source": [
        "X_test = (dtest['p_date']-means)/sds\n",
        "X_test = np.c_[np.ones(X_test.shape[0]),X_test]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oWjgtlo6Vjx"
      },
      "source": [
        "Время обучения!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMXxAKADK6w-"
      },
      "source": [
        "Решим задачу встроенными методами (точка отсчета):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-V3sYJDK5a1",
        "outputId": "d7ae2ad9-8f62-4ab3-8c93-2d8a104b49bb"
      },
      "source": [
        "regr = LinearRegression().fit(X, y)\n",
        "\n",
        "print(regr.intercept_)\n",
        "print(regr.coef_)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6.466887640016402\n",
            "[0.         0.03783491]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bv5ozPnBLA3l"
      },
      "source": [
        "Теперь наши:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_Nq-T4d4uIs",
        "outputId": "f0a1f2f1-67dc-417a-f8ea-45e1d46b91d5"
      },
      "source": [
        "# Full\n",
        "full_gd = LinearReg(gd_type='full')\n",
        "full_gd.fit(X,y)\n",
        "print(full_gd.w)\n",
        "\n",
        "y_test_pred = full_gd.predict(X_test)\n",
        "print(\"Test MSE full = %.4f\" % mean_squared_error(dtest['log_trip_duration'], y_test_pred))\n",
        "print(\"Test R2 full = %.4f\" % r2_score(dtest['log_trip_duration'], y_test_pred))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.46681911 0.03783451]\n",
            "Test MSE full = 0.6282\n",
            "Test R2 full = 0.0024\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nT0ZmXepEbTm",
        "outputId": "8ee57029-2e4b-49f2-95c7-4f98331c763b"
      },
      "source": [
        "# Stochastic\n",
        "stoch_gd = LinearReg(gd_type='stochastic', eta = 1)\n",
        "stoch_gd.fit(X,y)\n",
        "print(stoch_gd.w)\n",
        "\n",
        "y_test_pred = stoch_gd.predict(X_test)\n",
        "print(\"Test MSE stochastic = %.4f\" % mean_squared_error(dtest['log_trip_duration'], y_test_pred))\n",
        "print(\"Test R2 stochastic = %.4f\" % r2_score(dtest['log_trip_duration'], y_test_pred))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.52921584 0.09017749]\n",
            "Test MSE stochastic = 0.6347\n",
            "Test R2 stochastic = -0.0079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWGWwxX8BjYI"
      },
      "source": [
        "Видим, что оба метода сошлись к похожим значениям на базовых параметрах. При этом R2 говорит, что модель так себе (ну мы и не ожидали многого от одной переменной). Еще видно, что полный градиент сошелся лучше (ближе к истинному значению). Не удивительно, ведь данных не очень много и полный градиент быстро сходится, пока случайный скачет около решения. Теперь давайте варьировать параметры:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9o6lKVBOByxn",
        "outputId": "8576d6ce-fd81-4600-f485-7c68c540443c"
      },
      "source": [
        "for max_iters in range(500, 3500, 500):\n",
        "  print('Number of iterations: %.f' % max_iters)\n",
        "  full_gd = LinearReg(gd_type='full', max_iter = max_iters)\n",
        "  full_gd.fit(X,y)\n",
        "  y_test_pred = full_gd.predict(X_test)\n",
        "  print(\"Test MSE full = %.4f\" % mean_squared_error(dtest['log_trip_duration'], y_test_pred))\n",
        "  print(\"Test R2 full = %.4f\" % r2_score(dtest['log_trip_duration'], y_test_pred))\n",
        "\n",
        "  stoch_gd = LinearReg(gd_type='stochastic', max_iter = max_iters)\n",
        "  stoch_gd.fit(X,y)\n",
        "  y_test_pred = stoch_gd.predict(X_test)\n",
        "  print(\"Test MSE stochastic = %.4f\" % mean_squared_error(dtest['log_trip_duration'], y_test_pred))\n",
        "  print(\"Test R2 stochastic = %.4f\" % r2_score(dtest['log_trip_duration'], y_test_pred))\n",
        "\n",
        "  print('\\n')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of iterations: 500\n",
            "Test MSE full = 0.6282\n",
            "Test R2 full = 0.0024\n",
            "Test MSE stochastic = 0.9187\n",
            "Test R2 stochastic = -0.4590\n",
            "\n",
            "\n",
            "Number of iterations: 1000\n",
            "Test MSE full = 0.6282\n",
            "Test R2 full = 0.0024\n",
            "Test MSE stochastic = 0.6347\n",
            "Test R2 stochastic = -0.0079\n",
            "\n",
            "\n",
            "Number of iterations: 1500\n",
            "Test MSE full = 0.6282\n",
            "Test R2 full = 0.0024\n",
            "Test MSE stochastic = 0.6568\n",
            "Test R2 stochastic = -0.0431\n",
            "\n",
            "\n",
            "Number of iterations: 2000\n",
            "Test MSE full = 0.6282\n",
            "Test R2 full = 0.0024\n",
            "Test MSE stochastic = 0.6568\n",
            "Test R2 stochastic = -0.0431\n",
            "\n",
            "\n",
            "Number of iterations: 2500\n",
            "Test MSE full = 0.6282\n",
            "Test R2 full = 0.0024\n",
            "Test MSE stochastic = 0.6568\n",
            "Test R2 stochastic = -0.0431\n",
            "\n",
            "\n",
            "Number of iterations: 3000\n",
            "Test MSE full = 0.6282\n",
            "Test R2 full = 0.0024\n",
            "Test MSE stochastic = 0.6568\n",
            "Test R2 stochastic = -0.0431\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_h62HnaFTCp"
      },
      "source": [
        "Учитывая, что мы используем seed в SGD, для обоих методов есть определенное максимальное число итераций до остановки при текущих параметрах. До достижения этого количества мы обучаемся лучше (без учета случайной природы SGD). Дальнейшие увеличение параметра не имеет смысла (остановка по другому критерию). Выше видно, что после 1500 итераций изменений нет для SGD, а для полного - уже для 500+. Все ожидаемо. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-wMYmFgH1F4",
        "outputId": "fa9bef29-0b9d-48f6-9cae-2799a0314cc5"
      },
      "source": [
        "for etas in np.logspace(1, -5, num =7):\n",
        "  print('Eta: %.5f' % etas)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eta: 10.00000\n",
            "Eta: 1.00000\n",
            "Eta: 0.10000\n",
            "Eta: 0.01000\n",
            "Eta: 0.00100\n",
            "Eta: 0.00010\n",
            "Eta: 0.00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEC5FDNkF9yc",
        "outputId": "41baba71-b067-471f-ce91-f499fc3d5da6"
      },
      "source": [
        "for etas in np.logspace(0, -5, num =6):\n",
        "  print('Eta: %.5f' % etas)\n",
        "  full_gd = LinearReg(gd_type='full', eta = etas)\n",
        "  full_gd.fit(X,y)\n",
        "  y_test_pred = full_gd.predict(X_test)\n",
        "  print(\"Test MSE full = %.4f\" % mean_squared_error(dtest['log_trip_duration'], y_test_pred))\n",
        "  print(\"Test R2 full = %.4f\" % r2_score(dtest['log_trip_duration'], y_test_pred))\n",
        "\n",
        "  stoch_gd = LinearReg(gd_type='stochastic', eta = etas)\n",
        "  stoch_gd.fit(X,y)\n",
        "  y_test_pred = stoch_gd.predict(X_test)\n",
        "  print(\"Test MSE stochastic = %.4f\" % mean_squared_error(dtest['log_trip_duration'], y_test_pred))\n",
        "  print(\"Test R2 stochastic = %.4f\" % r2_score(dtest['log_trip_duration'], y_test_pred))\n",
        "\n",
        "  print('\\n')"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eta: 1.00000\n",
            "Test MSE full = 42.4542\n",
            "Test R2 full = -66.4253\n",
            "Test MSE stochastic = 0.6347\n",
            "Test R2 stochastic = -0.0079\n",
            "\n",
            "\n",
            "Eta: 0.10000\n",
            "Test MSE full = 0.6282\n",
            "Test R2 full = 0.0024\n",
            "Test MSE stochastic = 0.6826\n",
            "Test R2 stochastic = -0.0841\n",
            "\n",
            "\n",
            "Eta: 0.01000\n",
            "Test MSE full = 0.6282\n",
            "Test R2 full = 0.0024\n",
            "Test MSE stochastic = 13.6539\n",
            "Test R2 stochastic = -20.6850\n",
            "\n",
            "\n",
            "Eta: 0.00100\n",
            "Test MSE full = 1.3856\n",
            "Test R2 full = -1.2006\n",
            "Test MSE stochastic = 37.8378\n",
            "Test R2 stochastic = -59.0936\n",
            "\n",
            "\n",
            "Eta: 0.00010\n",
            "Test MSE full = 28.6421\n",
            "Test R2 full = -44.4891\n",
            "Test MSE stochastic = 42.1521\n",
            "Test R2 stochastic = -65.9454\n",
            "\n",
            "\n",
            "Eta: 0.00001\n",
            "Test MSE full = 40.8110\n",
            "Test R2 full = -63.8156\n",
            "Test MSE stochastic = 42.4441\n",
            "Test R2 stochastic = -66.4092\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAOhhRivJxXs"
      },
      "source": [
        "Тут тоже все согласуется с интуицией: если сделать eta очень маленькой, то все шаги сильно сожмутся. Это не позволит нам сойтись к решению. Так на примере выше: чем меньше eta, тем раньше (с худшей моделью) мы останавливаемся, так как быстрее достигаем критерия остановы. В то же время слишком большая eta не позволяет сойтись вообще, так как шаги большые и нас швыряет. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNJSqm8duVUj"
      },
      "source": [
        "**Задание 5 (2 балла)**. Постройте графики (на одной и той же картинке) зависимости величины функции потерь от номера итерации для полного и  стохастического градиентного спусков. Сделайте выводы о скорости сходимости различных модификаций градиентного спуска.\n",
        "\n",
        "Не забывайте о том, что должны получиться *красивые* графики!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "E7j6QWmtNEtd",
        "outputId": "00922fb8-7e23-4298-a7be-c277da74ca0d"
      },
      "source": [
        "fig, ax = plt.subplots(figsize = (12,8))\n",
        "\n",
        "ax.plot(full_gd.loss_history, label = 'Полный GD')\n",
        "ax.plot(stoch_gd.loss_history, label = 'Стохастический GD')\n",
        "ax.set_title('Сходимость MSE по шагам GD')\n",
        "ax.set_xlabel('Номер шага')\n",
        "ax.set_ylabel('MSE')\n",
        "ax.legend()\n",
        "\n",
        "ax.grid(True)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRDZD8k4Ohfg"
      },
      "source": [
        "Видно, что полный градиент сходится плавно, но надежно - критерий остановы достигается еще до 600 итерации. В то же время, стохастический градиент почти мгновенно скачет близко к оптимальным значениям, а потом скачет вокруг него (не сходясь окончательно). \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1NRgPkeuVUr"
      },
      "source": [
        "** Задание 6 (бонус) (0.01 балла)**.  Вставьте картинку с вашим любимым мемом в этот Jupyter Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooLLNAAbw6u9"
      },
      "source": [
        "![picture](https://drive.google.com/uc?export=view&id=18K6yEtApR3L8hctQ8vWgau4oF2uYX1gN) \n"
      ]
    }
  ]
}